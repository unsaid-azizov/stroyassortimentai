"""
–°–µ—Ä–≤–∏—Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ 1C –≤ Redis.

–õ–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ export_1c_catalog_to_csv.py:
1. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã –∏ —Ç–æ–≤–∞—Ä—ã –∏–∑ GET /GetGroups
2. Flatten –≤ —Å–ø–∏—Å–æ–∫ —Å group_name, group_code, item_code, item_name
3. –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –í–°–ï–ú —Ç–æ–≤–∞—Ä–∞–º –∏–∑ POST /GetDetailedItems (–±–∞—Ç—á–∞–º–∏)
4. Merge –¥–∞–Ω–Ω—ã—Ö
5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis –∫–∞–∫ JSON –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤

–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è:
- –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–ø–µ—Ä–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è)
- –ö–∞–∂–¥—ã–π —á–∞—Å —á–µ—Ä–µ–∑ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
- –í—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ API endpoint
"""
import os
import json
import asyncio
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

import httpx
from httpx import HTTPStatusError, RequestError
import redis.asyncio as redis

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è 1C API (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ C1_*)
ONEC_BASE_URL = "http://172.16.77.34/stroyast_test/hs/Ai"  # –ë–∞–∑–æ–≤—ã–π URL –±–µ–∑ endpoint
ONEC_USERNAME = os.getenv("C1_API_USER", "Admin")
ONEC_PASSWORD = os.getenv("C1_API_PASSWORD", "789654")
ONEC_TIMEOUT = int(os.getenv("C1_API_TIMEOUT_SECONDS", "60"))

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")  # localhost –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏, –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –Ω–∞ redis:6379 –≤ Docker
REDIS_CATALOG_KEY = "catalog:products"
REDIS_CATALOG_METADATA_KEY = "catalog:metadata"
REDIS_TTL = 7200  # 2 —á–∞—Å–∞

# –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è GetDetailedItems
BATCH_SIZE = 50


class CatalogSyncService:
    """–°–µ—Ä–≤–∏—Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞."""

    def __init__(self):
        self.redis_client: Optional[redis.Redis] = None
        self.is_syncing = False
        self.last_sync_time: Optional[datetime] = None
        self.last_sync_success = False
        self.last_error: Optional[str] = None

    async def init_redis(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –∫–ª–∏–µ–Ω—Ç–∞."""
        if not self.redis_client:
            self.redis_client = await redis.from_url(
                REDIS_URL,
                encoding="utf-8",
                decode_responses=True
            )
            logger.info(f"‚úÖ Redis client initialized: {REDIS_URL}")

    async def close_redis(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ Redis –∫–ª–∏–µ–Ω—Ç–∞."""
        if self.redis_client:
            await self.redis_client.close()
            self.redis_client = None
            logger.info("Redis client closed")

    async def get_all_groups(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã –∏ —Ç–æ–≤–∞—Ä—ã –∏–∑ GetGroups.

        Returns:
            {"groups": [{"–Ω–∞–∑–≤–∞–Ω–∏–µ": "...", "–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞": "...", "items": [{"–Ω–∞–∑–≤–∞–Ω–∏–µ": "...", "–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞": "..."}]}, ...]}
        """
        logger.info("üì¶ Fetching catalog from 1C GetGroups API...")

        async with httpx.AsyncClient(timeout=ONEC_TIMEOUT) as client:
            try:
                response = await client.get(
                    f"{ONEC_BASE_URL}/GetGroups",
                    auth=(ONEC_USERNAME, ONEC_PASSWORD),
                    headers={
                        "Content-Type": "application/json",
                        "Accept": "application/json"
                    }
                )
                response.raise_for_status()
                data = response.json()

                groups_count = len(data.get('groups', []))
                items_count = sum(len(g.get('items', [])) for g in data.get('groups', []))

                logger.info(f"   ‚úÖ Received {groups_count} groups, {items_count} items")
                return data

            except (HTTPStatusError, RequestError) as e:
                logger.error(f"   ‚ùå Error fetching groups: {e}")
                return {"groups": []}

    async def get_detailed_items_batch(
        self,
        item_codes: List[str],
        batch_num: int = 0,
        total_batches: int = 0
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Å–ø–∏—Å–∫—É —Ç–æ–≤–∞—Ä–æ–≤.

        Args:
            item_codes: –°–ø–∏—Å–æ–∫ –∫–æ–¥–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
            batch_num: –ù–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
            total_batches: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π

        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        if not item_codes:
            return []

        batch_info = f"[Batch {batch_num}/{total_batches}]" if total_batches > 0 else ""
        logger.info(f"   üîç {batch_info} Fetching details for {len(item_codes)} items...")

        async with httpx.AsyncClient(timeout=ONEC_TIMEOUT) as client:
            try:
                response = await client.post(
                    f"{ONEC_BASE_URL}/GetDetailedItems",
                    json={"items": item_codes},
                    auth=(ONEC_USERNAME, ONEC_PASSWORD),
                    headers={
                        "Content-Type": "application/json; charset=utf-8",
                        "Accept": "application/json"
                    }
                )
                response.raise_for_status()

                data = response.json()
                items = data.get('items', [])

                logger.info(f"      ‚úÖ Received {len(items)} detailed items")
                return items

            except (HTTPStatusError, RequestError) as e:
                logger.error(f"      ‚ùå Error fetching batch: {e}")
                return []

    async def get_all_detailed_items(self, item_codes: List[str]) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º (–±–∞—Ç—á–∞–º–∏).

        Args:
            item_codes: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–¥–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        logger.info(f"\nüìã Fetching detailed info for {len(item_codes)} items...")
        logger.info(f"   Batch size: {BATCH_SIZE}")

        all_items = []
        total_batches = (len(item_codes) + BATCH_SIZE - 1) // BATCH_SIZE

        for i in range(0, len(item_codes), BATCH_SIZE):
            batch = item_codes[i:i + BATCH_SIZE]
            batch_num = (i // BATCH_SIZE) + 1

            items = await self.get_detailed_items_batch(batch, batch_num, total_batches)
            all_items.extend(items)

            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i + BATCH_SIZE < len(item_codes):
                await asyncio.sleep(0.5)

        logger.info(f"\n   ‚úÖ Total detailed items received: {len(all_items)}/{len(item_codes)}")
        return all_items

    def flatten_catalog(self, catalog: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞—Ç–∞–ª–æ–≥–∞ –≤ flat —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤.

        Args:
            catalog: {"groups": [...]}

        Returns:
            [{"group_name": "...", "group_code": "...", "item_code": "...", "item_name": "..."}, ...]
        """
        logger.info("\nüîÑ Flattening catalog structure...")

        flat_items = []
        for group in catalog.get('groups', []):
            group_name = group.get('–Ω–∞–∑–≤–∞–Ω–∏–µ', '')
            group_code = group.get('–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞', '')

            for item in group.get('items', []):
                flat_items.append({
                    'group_name': group_name,
                    'group_code': group_code,
                    'item_code': item.get('–Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞', ''),
                    'item_name': item.get('–Ω–∞–∑–≤–∞–Ω–∏–µ', '')
                })

        logger.info(f"   ‚úÖ Created {len(flat_items)} flat records")
        return flat_items

    def clean_numeric_fields(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û—á–∏—â–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –æ—Ç –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤.
        
        1C API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–∞ —Å –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–º–∏ –ø—Ä–æ–±–µ–ª–∞–º–∏ (\xa0): "1 250", "2 500"
        –û—á–∏—â–∞–µ–º –∏—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞.
        """
        # –ü–æ–ª—è –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–∞ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
        numeric_fields = [
            '–¢–æ–ª—â–∏–Ω–∞', '–®–∏—Ä–∏–Ω–∞', '–î–ª–∏–Ω–∞',  # –†–∞–∑–º–µ—Ä—ã –≤ –º–º
            '–û—Å—Ç–∞—Ç–æ–∫',  # –û—Å—Ç–∞—Ç–æ–∫ –Ω–∞ —Å–∫–ª–∞–¥–µ
            '–ü–ª–æ—Ç–Ω–æ—Å—Ç—å–∫–≥–º–û–±—â–∏–µ',  # –∫–≥/–º¬≥
            '–°—Ä–æ–∫–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞–¥–Ω–û–±—â–∏–µ',  # –°—Ä–æ–∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –≤ –¥–Ω—è—Ö
            '–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å–û–±—â–∏–µ',  # –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å (—Ä–µ–π—Ç–∏–Ω–≥)
        ]

        cleaned = item.copy()

        for field in numeric_fields:
            if field in cleaned and cleaned[field]:
                value = cleaned[field]
                if isinstance(value, str):
                    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã (–≤–∫–ª—é—á–∞—è –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ \xa0)
                    cleaned[field] = value.replace(' ', '').replace('\xa0', '')

        return cleaned

    def merge_data(
        self,
        flat_items: List[Dict[str, Any]],
        detailed_items: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç flat —Å–ø–∏—Å–æ–∫ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.

        –õ–æ–≥–∏–∫–∞ –∫–∞–∫ –≤ export_1c_catalog_to_csv.py:
        - –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å detailed_map –ø–æ –∫–æ–¥—É –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—é
        - –î–ª—è –∫–∞–∂–¥–æ–≥–æ flat item –∏—â–µ–º –¥–µ—Ç–∞–ª–∏
        - Merge –≤—Å–µ—Ö –ø–æ–ª–µ–π: {...flat, ...detailed}

        Args:
            flat_items: –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–≥—Ä—É–ø–ø–∞, –Ω–∞–∑–≤–∞–Ω–∏–µ)
            detailed_items: –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Ä–∞–∑–º–µ—Ä—ã, —Ü–µ–Ω—ã, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)

        Returns:
            –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ —Å–æ –≤—Å–µ–º–∏ –ø–æ–ª—è–º–∏ (–∞–Ω–∞–ª–æ–≥ CSV)
        """
        logger.info("\nüîó Merging data...")

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        detailed_map = {}
        for item in detailed_items:
            # –ò–Ω–æ–≥–¥–∞ –∫–æ–¥ –ø—É—Å—Ç–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–∫ –∫–ª—é—á
            code = item.get('–ö–æ–¥', '') or item.get('–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '')
            if code:
                detailed_map[code] = item

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
        merged = []
        matched = 0

        for flat in flat_items:
            item_code = flat['item_code']
            item_name = flat['item_name']

            # –ò—â–µ–º –¥–µ—Ç–∞–ª–∏ –ø–æ –∫–æ–¥—É –∏–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            detailed = detailed_map.get(item_code) or detailed_map.get(item_name)

            if detailed:
                matched += 1
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø–æ–ª—è (–∫–∞–∫ –≤ CSV)
                merged_item = {
                    **flat,  # group_name, group_code, item_code, item_name
                    **detailed  # –≤—Å–µ –ø–æ–ª—è –∏–∑ API
                }
                # –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –æ—Ç –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
                merged_item = self.clean_numeric_fields(merged_item)
                merged.append(merged_item)
            else:
                # –ï—Å–ª–∏ –¥–µ—Ç–∞–ª–µ–π –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                merged.append(flat)

        logger.info(f"   ‚úÖ Matched: {matched}/{len(flat_items)} items")
        return merged

    async def save_to_redis(self, data: List[Dict[str, Any]]) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ –≤ Redis –∫–∞–∫ JSON –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤.

        Args:
            data: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ CSV)

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
        """
        if not data:
            logger.warning("‚ö†Ô∏è  No data to save to Redis")
            return False

        logger.info(f"\nüíæ Saving {len(data)} items to Redis...")

        try:
            await self.init_redis()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ç–∞–ª–æ–≥ –≤ JSON
            catalog_json = json.dumps(data, ensure_ascii=False)
            await self.redis_client.set(
                REDIS_CATALOG_KEY,
                catalog_json,
                ex=REDIS_TTL
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                "items_count": len(data),
                "last_sync": datetime.utcnow().isoformat(),
                "ttl_seconds": REDIS_TTL
            }
            metadata_json = json.dumps(metadata, ensure_ascii=False)
            await self.redis_client.set(
                REDIS_CATALOG_METADATA_KEY,
                metadata_json,
                ex=REDIS_TTL
            )

            logger.info(f"   ‚úÖ Saved to Redis: {len(data)} items")
            logger.info(f"   üïê TTL: {REDIS_TTL} seconds ({REDIS_TTL // 3600} hours)")
            return True

        except Exception as e:
            logger.error(f"   ‚ùå Error saving to Redis: {e}")
            return False

    async def sync_catalog(self) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞.

        –ê–ª–≥–æ—Ä–∏—Ç–º (–∞–Ω–∞–ª–æ–≥–∏—á–µ–Ω export_1c_catalog_to_csv.py):
        1. –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ GetGroups
        2. Flatten –≤ —Å–ø–∏—Å–æ–∫
        3. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–æ–¥—ã —Ç–æ–≤–∞—Ä–æ–≤
        4. –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –±–∞—Ç—á–∞–º–∏ –∏–∑ GetDetailedItems
        5. Merge –¥–∞–Ω–Ω—ã—Ö
        6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis

        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        """
        if self.is_syncing:
            logger.warning("‚ö†Ô∏è  Sync already in progress, skipping...")
            return {
                "status": "skipped",
                "reason": "sync_in_progress"
            }

        self.is_syncing = True
        sync_start = datetime.utcnow()

        logger.info("\n" + "=" * 80)
        logger.info("üöÄ CATALOG SYNC STARTED")
        logger.info("=" * 80)
        logger.info(f"Start time: {sync_start.isoformat()}")

        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
            catalog = await self.get_all_groups()

            if not catalog.get('groups'):
                raise Exception("Failed to fetch catalog from 1C API")

            # 2. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ flat —Å–ø–∏—Å–æ–∫
            flat_items = self.flatten_catalog(catalog)

            # 3. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–æ–¥—ã —Ç–æ–≤–∞—Ä–æ–≤
            all_codes = list(set(item['item_code'] for item in flat_items if item['item_code']))
            logger.info(f"\n   Unique item codes: {len(all_codes)}")

            # 4. –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ (–±–∞—Ç—á–∞–º–∏)
            detailed_items = await self.get_all_detailed_items(all_codes)

            # 5. –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            merged_data = self.merge_data(flat_items, detailed_items)

            # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis
            success = await self.save_to_redis(merged_data)

            if not success:
                raise Exception("Failed to save catalog to Redis")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            sync_end = datetime.utcnow()
            duration = (sync_end - sync_start).total_seconds()

            self.last_sync_time = sync_end
            self.last_sync_success = True
            self.last_error = None

            stats = {
                "status": "success",
                "items_count": len(merged_data),
                "groups_count": len(catalog.get('groups', [])),
                "start_time": sync_start.isoformat(),
                "end_time": sync_end.isoformat(),
                "duration_seconds": duration
            }

            logger.info("\n" + "=" * 80)
            logger.info("‚úÖ CATALOG SYNC COMPLETED")
            logger.info(f"   Items: {stats['items_count']}")
            logger.info(f"   Duration: {duration:.2f}s")
            logger.info("=" * 80 + "\n")

            return stats

        except Exception as e:
            self.last_sync_success = False
            self.last_error = str(e)

            logger.error("\n" + "=" * 80)
            logger.error("‚ùå CATALOG SYNC FAILED")
            logger.error(f"   Error: {e}")
            logger.error("=" * 80 + "\n")

            return {
                "status": "error",
                "error": str(e),
                "start_time": sync_start.isoformat()
            }

        finally:
            self.is_syncing = False

    async def get_catalog_from_redis(self) -> Optional[List[Dict[str, Any]]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ Redis.

        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        """
        try:
            await self.init_redis()

            catalog_json = await self.redis_client.get(REDIS_CATALOG_KEY)
            if not catalog_json:
                logger.warning("‚ö†Ô∏è  Catalog not found in Redis")
                return None

            catalog = json.loads(catalog_json)
            logger.info(f"‚úÖ Loaded {len(catalog)} items from Redis")
            return catalog

        except Exception as e:
            logger.error(f"‚ùå Error loading catalog from Redis: {e}")
            return None

    async def get_sync_status(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏.

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        """
        await self.init_redis()

        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ Redis
        metadata_json = await self.redis_client.get(REDIS_CATALOG_METADATA_KEY)
        metadata = json.loads(metadata_json) if metadata_json else None

        return {
            "is_syncing": self.is_syncing,
            "last_sync_time": self.last_sync_time.isoformat() if self.last_sync_time else None,
            "last_sync_success": self.last_sync_success,
            "last_error": self.last_error,
            "redis_metadata": metadata
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
catalog_sync_service = CatalogSyncService()
